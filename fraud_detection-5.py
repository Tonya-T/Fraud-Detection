# -*- coding: utf-8 -*-
"""Fraud_Detection_HighlyImbalancedDtat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pY92qyKvUz-7kauo-pyuAZboNRxT_8B5
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,recall_score,precision_score

data=pd.read_csv('fraudTrain.csv')
data.head()

data=data.dropna()

data.isnull().sum()

plt.figure(figsize=(10, 6))
sns.boxplot(x='is_fraud', y='amt', data=data, color='green')
plt.title('Transaction Amounts by Fraud/Non-Fraud')
plt.show()

fraud=data[data["is_fraud"]==1]
not_fraud=data[data["is_fraud"]==0]
print(fraud.shape[0])
print(not_fraud.shape[0])

not_fraud=not_fraud.sample(fraud.shape[0])
data=pd.concat([fraud,not_fraud])

unused_cols=['Unnamed: 0','first','last','unix_time','street','gender','job','dob','city','state','trans_num']
data.drop(columns=unused_cols,inplace=True)

data['trans_date_trans_time']=pd.to_datetime(data['trans_date_trans_time'])
data['trans_day']=data['trans_date_trans_time'].dt.day
data['trans_month']=data['trans_date_trans_time'].dt.month
data['trans_year']=data['trans_date_trans_time'].dt.year
data['trans_hour']=data['trans_date_trans_time'].dt.hour
data['is_night'] = data['trans_hour'].isin([21,22,23,0,1,2,3,4,5]).astype(int)
data.drop(columns=['trans_date_trans_time'],inplace=True)

data['distance_km'] = np.sqrt(
    (data['lat'] - data['merch_lat'])**2 +
    (data['long'] - data['merch_long'])**2
)
data

# Calculate the fraud rate (probability) for each merchant
merchant_fraud_rate = data.groupby('merchant')['is_fraud'].mean()

# Map this fraud rate back to the original DataFrame as a new feature
data['merchant_fraud_rate'] = data['merchant'].map(merchant_fraud_rate)
data['merchant_fraud_rate']

high_risk_threshold = 0.05  # e.g., 5%
data['high_risk_merchant'] = data['merchant_fraud_rate'] > high_risk_threshold
data['high_risk_merchant']

encoder=LabelEncoder()
data['category']=encoder.fit_transform(data['category'])
data['cc_num']=encoder.fit_transform(data['cc_num'])
data['merchant']=encoder.fit_transform(data['merchant'])

scaler=StandardScaler()
data['amt']=scaler.fit_transform(data[['amt']])
data['zip']=scaler.fit_transform(data[['zip']])
data['city_pop']=scaler.fit_transform(data[['city_pop']])
data['cc_num']=encoder.fit_transform(data['cc_num'])

data

X=data.drop('is_fraud',axis=1)
y=data['is_fraud']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)

import pickle

def evaluate_and_save_model(model, X_train, X_test, y_train, y_test, filename):
  model.fit(X_train, y_train)
  y_pred=model.predict(X_test)
  accuracy=accuracy_score(y_test, y_pred)
  print(f"{model.__class__.__name__}Accuracy:{accuracy:.4f}")
  print(f"\nclassification_report:\n{classification_report(y_test, y_pred)}")
  print("---------------")

  with open(filename, "wb") as file:
     pickle.dump(model, file)


  print(f"Model saved as {filename}")

import xgboost as xgb

from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import train_test_split

xgb_model = xgb.XGBClassifier(random_state=0)
evaluate_and_save_model(xgb_model, X_train, X_test, y_train, y_test, "xgb_model.pkl")
